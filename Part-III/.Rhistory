tweets <- (convFace[!is.na(convFace)])
head(tweets) # 앞부분 6줄 보기 - 줄 단위 문장 확인
str(tweets) # chr [1:76]
facebook <- file("C:/NCS/Rwork/Part-II/facebook_bigdata.txt", encoding="UTF-8")
facebook_data <- readLines(facebook) # 줄 단위 데이터 생성
facebook_corpus <- Corpus(VectorSource(facebook_data))
facebook_corpus
inspect(facebook_corpus) # 76개 자료집에 포함된 문자 수 제공
mergeUserDic(data.frame(c("R 프로그래밍","페이스북","소셜네트워크"), c("ncn")))
exNouns <- function(x) { paste(extractNoun(as.character(x)), collapse=" ")}
facebook_nouns <- sapply(facebook_corpus, exNouns)
facebook_nouns[1] # 단어만 추출된 첫 줄 보기
facebook_nouns[1] # 단어만 추출된 첫 줄 보기
myCorputfacebook <- Corpus(VectorSource(facebook_nouns))
myCorputfacebook # Content:  documents: 76
myCorputfacebook # Content:  documents: 76
myCorputfacebook <- tm_map(myCorputfacebook, removePunctuation) # 문장부호 제거
myCorputfacebook <- tm_map(myCorputfacebook, removeNumbers) # 수치 제거
myCorputfacebook <- tm_map(myCorputfacebook, tolower) # 소문자 변경
myCorputfacebook <- tm_map(myCorputfacebook, removeWords, stopwords('english')) # 불용어제거
inspect(myCorputfacebook[1:5]) # 데이터 전처리 결과 확인
myCorputfacebook_txt <- tm_map(myCorputfacebook, PlainTextDocument)
myCorputfacebook_txt
myCorputfacebook_txt <- TermDocumentMatrix(myCorputfacebook_txt$content, control=list(wordLengths=c(2,Inf)))
myCorputfacebook_txt
myCorputfacebook_txt <- TermDocumentMatrix(myCorputfacebook_txt$meta, control=list(wordLengths=c(2,Inf)))
myCorputfacebook_txt <- TermDocumentMatrix(myCorputfacebook_txt, control=list(wordLengths=c(2,Inf)))
facebook_data
facebook_corpus <- Corpus(VectorSource(facebook_data))
facebook_corpus
inspect(facebook_corpus) # 76개 자료집에 포함된 문자 수 제공
facebook_corpus
str(facebook_data) # chr [1:76]
facebook_data
facebook[1]
facebook[[1]]
facebook_data[1]
facebook_corpus[1]
facebook_data
facebook_corpus <- Corpus(VectorSource(facebook_data))
facebook_corpus
inspect(facebook_corpus) # 76개 자료집에 포함된 문자 수 제공
facebook_corpus
exNouns <- function(x) { paste(extractNoun(as.character(x)), collapse=" ")}
facebook_nouns <- sapply(facebook_corpus, exNouns)
facebook_nouns[1] # 단어만 추출된 첫 줄 보기
myCorputfacebook_txt <- tm_map(myCorputfacebook, PlainTextDocument)
myCorputfacebook_txt
myCorputfacebook_txt <- TermDocumentMatrix(myCorputfacebook_txt, control=list(wordLengths=c(2,Inf)))
myCorputfacebook_txt
library(SnowballC)
myCorputfacebook_txt <- tm_map(myCorputfacebook,stemDocument) #평서문으로 변경
myCorputfacebook_txt <- PlainTextDocument(myCorputfacebook)
myCorputfacebook_txt
myCorputfacebook_txt <- TermDocumentMatrix(myCorputfacebook_txt, control=list(wordLengths=c(2,Inf)))
myCorputfacebook_txt
install.packages("http://cran.r-project.org/bin/windows/contrib/3.0/tm_0.5-10.zip",repos=NULL)
library(tm)
library(ggmap)
pop <- read.csv("C:/NCS/Rwork/Part-II/population201506.csv",header=T)
str(pop)
house <- as.numeric(str_replace_all(pop$세대수, ',',''))
library(stringr)
region <- pop$지역명
lon <- pop$LON # 위도
region <- pop$지역명
lon <- pop$LON # 위도
lat <- pop$LAT # 경도
house <- as.numeric(str_replace_all(pop$세대수, ',',''))
df <- as.data.frame(region, lon, lat, house)
str(df)
df <- data.frame(region, lon, lat, house)
str(df)
library(ggmap)
map1 <- get_map("Jeonju", zoom=7 ,  maptype='roadmap')
map2 <- ggmap(map1)
map2 + geom_point(aes(x=lon,y=lat,color=house,size=house),data=df)
map3 <- map2 + geom_point(aes(x=lon,y=lat,color=factor(house),size=factor(house),data=df)
map3 <- map2 + geom_point(aes(x=lon,y=lat,color=factor(house),size=factor(house)),data=df)
map3 + geom_text(data=df, aes(x=lon+0.01, y=lat+0.18,label=region),size=3)
map1 <- get_map("Jeonju", zoom=7 ,  maptype='roadmap')
map2 + geom_point(aes(x=lon,y=lat,color=house,size=house),data=df)
map3 <- map2 + geom_point(aes(x=lon,y=lat,color=factor(house),size=factor(house)),data=df)
map3 + geom_text(data=df, aes(x=lon+0.01, y=lat+0.18,label=region),size=3)
getwd()
setwd("c:/NCS/Rwork/Part-III")
getwd()
data <- read.csv("descriptive.csv", header=TRUE)
head(data) # 데이터셋 확인
str(data)
head(data) # 데이터셋 확인
dim(data) # 행(300)과 열(8) 정보 - 차원보기
length(data) # 열(8) 길이
length(data$survey) #survey 컬럼의 관찰치 - 행(300)
str(data) # 데이터 구조보기 -> 데이터 종류,행/열,data
str(data$survey)
summary(data)
str(data) # 데이터 구조보기 -> 데이터 종류,행/열,data
range(data$pass)
summary(data$pass, ra.rm=T)
range(data$pass, na.rm=T)
length(data$gender)
summary(data$gender) # 최소,최대,중위수,평균-의미없음
table(data$gender) # 각 성별 빈도수 - outlier 확인-> 0, 5
data <- subset(data, data$gender == 1 | data$gender == 2) # 성별 outlier 제거
x <- table(data$gender) # 성별에 대한 빈도수 저장
x # outlier 제거 확인
barplot(x) # 범주형(명목/서열척도) 시각화 -> 막대차트
prop.table(x) # 비율 계산 : 0< x <1 사이의 값
prop.table(x)
round(y*100, 2) #백분율 적용(소수점 2자리)
prop.table(x) # 비율 계산 : 0< x <1 사이의 값
y <-  prop.table(x)
round(y*100, 2) #백분율 적용(소수점 2자리)
rm(list=ls())
data <- read.csv("descriptive.csv", header=TRUE)
head(data) # 데이터셋 확인
data <- subset(data, data$gender == 1 | data$gender == 2) # 성별 outlier 제거
x <- table(data$gender) # 성별에 대한 빈도수 저장
prop.table(x) # 비율 계산 : 0< x <1 사이의 값
y <-  prop.table(x)
round(y*100, 2) #백분율 적용(소수점 2자리)
length(data$level) # 학력수준 - 서열
summary(data$level) # 명목척도와 함께 의미없음
table(data$level)  # 빈도분석 - 의미있음
x1 <- table(data$level) # 각 학력수준에 빈도수 저장
x1
barplot(x1) # 명목/서열척도 -> 막대차트
survey <- data$survey
survey
x1<-table(survey) # 빈도수
x1
v
summary(survey) # 만족도(5점 척도)인 경우 의미 있음 -> 2.6(평균이상)
x1
hist(survey) # 등간척도 시각화 -> 히스토그림
hist(survey) # 등간척도 시각화 -> 히스토그림
div.off()
dvc.off()
dvc.off()
length(data$cost)
summary(data$cost) # 요약통계량 - 의미있음(mean) - 8.784
mean(data$cost) # NA
data$cost
plot(data$cost)
data <- subset(data,data$cost >= 2 & data$cost <= 10) # 총점기준
data
x <- data$cost
x
mean(x) # 평균 : 5.354
median(x) # 5.4
min(x)
max(x)
range(x) # min ~ max
sort(x) # 오름차순
sort(x, decreasing=T) # 내림차순
var(x) # 분산
sd(x) # 표준편차는 분t산의 양의 제곱근
quantile(x, 1/4) # 1 사분위수 - 25%, 4.6
quantile(x, 3/4) # 3 사분위수 - 75%, 6.2
min(x) # 최소값
max(x) # 최대값
range(x) # 범위(min ~ max)
xx <- c(3,6,1,3,6,4,3,6)
xx
dev.off()
tb <- table(xx)
tb
max(tb)
xx <- c(3,6,1,3,6,4,3,3,6)
tb <- table(xx)
max(tb)
xx <- c(3,6,1,3,6,4,3,6)
tb <- table(xx)
max(tb)
which(tb==3)
max(table(x))
which(table(x)==18)
table(x)
table(x)[19]
var(x) # 분산
sd(x) # 표준편차는 분t산의 양의 제곱근
round(var(x),2) # 분산
sd(x) # 표준편차는 분t산의 양의 제곱근
var(x) # 분산
sqrt(sd(x)) # 표준편차는 분t산의 양의 제곱근
sqrt(var(x))
sd(X)
sd(x)
sd(x)^2
sqrt(var(x))
sd(x) # 표준편차는 분t산의 양의 제곱근
quantile(x, 1/4) # 1 사분위수 - 25%, 4.6
quantile(x, 3/4) # 3 사분위수 - 75%, 6.2
quantile(x, 1/4) # 1 사분위수 - 25%, 4.6
quantile(x, 3/4) # 3 사분위수 - 75%, 6.2
min(x) # 최소값
max(x) # 최대값
range(x) # 범위(min ~ max)
install.packages("moments")  # 왜도/첨도 위한 패키지 설치
library(moments)
cost <- data$cost # 정제된 data
cost
skewness(cost) # 0.2974908
skewness(cost) # 0.2974908
kurtosis(cost) # 2.683438
hist(cost)
mean(cost)
max(table(cost))
median(cost)
skewness(cost) # -0.2974908
mean(cost)
median(cost)
skewness(cost) # -0.2974908
mean(cost)
median(cost)
skewness(cost) # -0.2974908
kurtosis(cost) # 2.683438
hist(cost)
hist(cost, freq = F)
hist(cost)
hist(cost, freq = F)
lines(density(cost), col='blue')
x <- seq(0, 8, 0.1)
curve( dnorm(x, mean(cost), sd(cost)), col='red', add = T)
x
median(cost)
mean(cost)
qqnorm(cost, main="cost qq-ploy")
qqline(cost, col='red')
shapiro.test(cost)
shapiro.test(cost)
attach(data) #data를 붙여라! -> data$ 생략
length(cost)
summary(cost) # 요약통계량 - 의미있음(mean)
mean(cost) # 가장 의미있음
min(cost)
max(cost)
range(cost) # min ~ max
sd<- sd(cost, na.rm=T)
var(cost, na.rm=T)
sqrt(var(cost, na.rm=T))
sd(cost, na.rm=T)
shapiro.test(cost)
shapiro.test(cost)
sort(cost) # 오름차순
sort(cost, decreasing=T) # 내림차순
detach(data) # attach(data) 해제
test <-c(1:5,NA,10:20)
min(test) # NA 출력
max(test) # NA 출력
range(test) # NA 출력
mean(test) # NA 출력
min(test, na.rm=T) # na.rm=T 결측데이터 제거 방법1
max(test, na.rm=T)
range(test, na.rm=T)
mean(test, na.rm=T)
library(MASS)
data(Animals)
str(Animals)
setwd("c:/NCS/Rwork/Part-III")
data <- read.csv("descriptive.csv", header=TRUE)
head(data) # 데이터셋 확인
attach(data)
table(type)
table(pass)
hist(table(type))
dev.off()
hist(table(type))
table(type)
hist(table(pass))
table(pass)
tt <- table(type)
tp <- table(pass)
hist(tt)
hist(tt, freq = T)
hist(tt, freq = F)
hist(tt, freq = T)
pie(tt)
pit(tp)
pie(tp)
head(data) # 데이터셋 확인
mean(age)
sd(age)
skewness(age)
kurtosis(age)
hist(age, freq = F)
lines(density(age), col='blue')
x <- seq(35, 75, 1)
curve( dnorm(x, mean(age), sd(age)), col='red', add = T)
qqnorm(age, main="age qq-ploy")
qqline(age, col='red')
shapiro.test(age)
hist(tt, freq = T)
attach(data)
tt <- table(type)
tp <- table(pass)
detach(data)
function (height, ...)
barplot(tt, freq = T)
barplot(tp, freq = T)
barplot(tt)
barplot(tp)
x <- seq(35, 75, 0.1)
curve( dnorm(x, mean(age), sd(age)), col='red', add = T)
attach(data)
tt <- table(type)
tp <- table(pass)
barplot(tt)
barplot(tp)
pie(tt)
pie(tp)
hist(age, freq = F)
lines(density(age), col='blue')
x <- seq(35, 75, 0.1)
curve( dnorm(x, mean(age), sd(age)), col='red', add = T)
shapiro.test(age)
skewness(age)
kurtosis(age)
prop.table(x) # 비율 계산 : 0< x <1 사이의 값
y <-  prop.table(x)
round(y*100, 2) #백분율 적용(소수점 2자리)
data <- read.csv("descriptive.csv", header=TRUE)
head(data) # 데이터셋 확인
data <- subset(data, data$gender == 1 | data$gender == 2) # 성별 outlier 제거
x <- table(data$gender) # 성별에 대한 빈도수 저장
x # outlier 제거 확인
barplot(x) # 범주형(명목/서열척도) 시각화 -> 막대차트
prop.table(x) # 비율 계산 : 0< x <1 사이의 값
y <-  prop.table(x)
round(y*100, 2) #백분율 적용(소수점 2자리)
prop.tt
data <- read.csv("descriptive.csv", header=TRUE)
attach(data)
tt <- table(type)
tp <- table(pass)
prop.tt
prop.table(type)
attach(data)
prop.table(type)
tt <- table(type)
tt
prop.table(tt)
source('C:/NCS/Rwork/R-script/Part-III/제11장 연습문제.R', encoding = 'UTF-8')
source('C:/NCS/Rwork/R-script/Part-III/제11장 연습문제.R', encoding = 'UTF-8')
dev.off()
source('C:/NCS/Rwork/R-script/Part-III/제11장 연습문제.R', encoding = 'UTF-8')
install.packages("Hmisc") # 웹사이트 접속하여 패키지 설치
library(Hmisc) # 해당 패키지를 메모리 로딩
describe(data) # Hmisc 패키지에서 제공되는 함수
describe(data) # Hmisc 패키지에서 제공되는 함수
describe(data$gender) # 특정 변수(명목) 기술통계량 - 비율 제공
install.packages("prettyR")
library(prettyR)
freq(data) # 각 변수별 : 빈도, 결측치, 백분율, 특징-소수점 제공
data(Animals)
str(Animals)
detach()
dim(Animals)# Animals 데이터 셋 차원보기
describe(Animals)
freq(Animals)
library(prettyR)
freq(Animals)
brain <- Animals$brain
mean(brain)
var(brain)
mean(brain)
var(brain)
sd(brain)
sum(brain)
median(brain)
setwd("c:/NCS/Rwork/Part-III")
data <- read.csv("cleanDescriptive.csv", header=TRUE)
data # 확인
head(data) # 변수 확인
data <- read.csv("cleanDescriptive.csv", header=TRUE)
data # 확인
head(data) # 변수 확인
x <- data$level2 # 리코딩 변수 이용
y <- data$pass2 # 리코딩 변수 이용
x; y # 부모학력수준(x), 자녀대학진학여부(y)
result <- data.frame(Level=x, Pass=y) # 데이터 프레임 생성 - 데이터 묶음
dim(result) # 차원보기
result
table(result) # 빈도보기
install.packages("gmodels") # gmodels 패키지 설치
library(gmodels) # CrossTable() 함수 사용
install.packages("ggplot2") # diamonds 데이터 셋 사용을 위한 패키지 설치
library(ggplot2)
CrossTable(x=diamonds$color, y=diamonds$cut)
table(result) # 빈도보기
CrossTable(x=result$Level, y=result$Pass)
CrossTable(x=diamonds$color, y=diamonds$cut)
CrossTable(x=result$Level, y=result$Pass)
head(diamonds)
CrossTable(x=diamonds$color, y=diamonds$cut)
CrossTable(x=result$Level, y=result$Pass)
CrossTable(x=result$Level, y=result$Pass)
CrossTable(x=result$Level, y=result$Pass, chisq = T)
CrossTable(x=result$Level, y=result$Pass, chisq = T)
library(help="ggplot2")
library(help="ggplot2", Encoding(UTF-8))
library(help="ggplot2", Encoding("UTF-8"))
chisq.test(c(4,6,17,16,8,9))
data <- textConnection(
"스포츠음료종류  관측도수
1   41
2   30
3   51
4   71
5   61
")
x <- read.table(data, header=T)
x # 스포츠음료종류 관측도수
chisq.test(c(4,6,17,16,8,9))
CrossTable(x=result$Level, y=result$Pass, chisq = T)
result$Level
result$Pass
chisq.test(c(4,6,17,16,8,9))
?chisq.test
data <- textConnection(
"스포츠음료종류  관측도수
1   41
2   30
3   51
4   71
5   61
")
data <- textConnection(
"스포츠음료종류  관측도수
1   41
2   30
3   51
4   71
5   61
")
x <- read.table(data, header=T)
x # 스포츠음료종류 관측도수
chisq.test(x$관측도수)
data <-
"스포츠음료종류  관측도수
data <-
"스포츠음료종류  관측도수
1   41
2   30
3   51
4   71
5   61
"
data <- "스포츠음료종류  관측도수  1   41  2   30  3   51   4   71   5   61 ")
data <- c("스포츠음료종류  관측도수  1   41  2   30  3   51   4   71   5   61 ")
x <- read.table(data, header=T)
x <- data$level2 # 부모의 학력수준
data
data <- read.csv("cleanDescriptive.csv", header=TRUE)
x <- data$level2 # 부모의 학력수준
y <- data$pass2 # 자녀의 대학진학여부
CrossTable(x, y, chisq = TRUE) #p =  0.2507057
setwd("c:/NCS/Rwork/Part-III")
smoke <- read.csv("smoke.csv", header=TRUE)
head(smoke) # education, smoking 변수
names(smoke)
smoke$education[smoke$education==1,] <- '대졸'
smoke$education[smoke$education==1] <- '대졸'
smoke$education[smoke$education==2] <- '고졸'
smoke$education[smoke$education==3] <- '중졸'
smoke
smoke$smoking[smoke$smoking==1] <- '과다흡연'
smoke$smoking[smoke$smoking==2] <- '보통흡연'
smoke$smoking[smoke$smoking==3] <- '비흡연'
smoke
str(smoke)
CrossTable(smoke$education, smoke$smoking, chisq = T)
setwd("c:/NCS/Rwork/Part-III")
data <- read.csv("homogenity.csv", header=TRUE)
head(data)
data <- subset(data, !is.na(survey), c(method, survey))
head(data )
head(data)
data$method2[data$method==1] <- "방법1"
data$method2[data$method==2] <- "방법2"
data$method2[data$method==3] <- "방법3"
data$survey2[data$survey==1] <- "매우만족"
data$survey2[data$survey==2] <- "만족"
data$survey2[data$survey==3] <- "보통"
data$survey2[data$survey==4] <- "불만족"
data$survey2[data$survey==5] <- "매우불만족"
data$survey==1
data$survey2[data$survey==1] <- "1.매우만족"
data$survey2[data$survey==2] <- "2.만족"
data$survey2[data$survey==3] <- "3.보통"
data$survey2[data$survey==4] <- "4.불만족"
data$survey2[data$survey==5] <- "5.매우불만족"
table(data$method2, data$survey2)  # 교차표 생성 -> table(행,열)
CrossTable(data$method2, data$survey2)  # 교차표 생성 -> table(행,열)
chisq.test(data$method2, data$survey2)
CrossTable(data$method2, data$survey2, chisq = T)
chisq.test(data$method2, data$survey2)
setwd("c:/NCS/Rwork/Part-III")
response <- read.csv("response.csv", header=TRUE)
head(result) # 변수 보기
head(response) # 변수 보기
response$job[response$job==1] <-'1.학생'
response$job[response$job==2] <-'2.직장인'
response$job[response$job==3] <-'3.주부'
response$response[response$response==1] <- '무응답'
response$response[response$response==2] <- '낮음'
response$response[response$response==3] <- '높음'
head(response) # 변수 보기
CrossTable(response$job, response$response, chisq = T)
chisq.test(response$job, response$response)
table(response$job, response$response)
